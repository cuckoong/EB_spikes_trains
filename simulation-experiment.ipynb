{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5xT5gyZzcXd4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pystan\n",
    "import time\n",
    "import scipy.stats as stats\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3F-qPyRVq2Xj"
   },
   "source": [
    "## Simulation parameters and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EpC4_fxScXeQ",
    "outputId": "5b9cb390-c63d-48e5-d739-5b83461cee00"
   },
   "outputs": [],
   "source": [
    "def simulate(pars,seed):#simulation       \n",
    "\n",
    "    import scipy.special as sc\n",
    "    #Number of simulation trials\n",
    "    N_sim = pars['N_sim'] \n",
    "\n",
    "    #NB-means\n",
    "    r =pars['r']  \n",
    "\n",
    "    #neurons numbers\n",
    "    M = pars['M']\n",
    "\n",
    "    #network weights\n",
    "    b0= pars['b0']\n",
    "    #b = np.random.uniform(-0.9,0.9,M) #random select from -1 to 1; \n",
    "    b = pars['b']\n",
    "    #link function parameters\n",
    "    loggam=pars['loggam']\n",
    "    gam = np.exp(loggam)\n",
    "  \n",
    "    #sigma for beta prior\n",
    "    s = pars['s']\n",
    "\n",
    "    #trial bins\n",
    "    K = pars['K'] #bins\n",
    "\n",
    "    #input from other neuons\n",
    "    x = np.ones(K)*3\n",
    "    rng0 = np.random.default_rng(seed=2)\n",
    "    for i in range(M-1):\n",
    "        x_n = rng0.poisson(rng0.choice([6,8,7,5],p=[1/4]*4,size = 1),size = K)\n",
    "        x = np.row_stack([x,x_n])\n",
    "\n",
    "\n",
    "    # preset Î¸ \n",
    "    mu = np.zeros(K)\n",
    "\n",
    "    #preset y-true and y-simulatoin\n",
    "    y_true = np.zeros(K)\n",
    "    y_sim = np.zeros((K,N_sim))\n",
    "\n",
    "    # true y value\n",
    "    for i in range(K):\n",
    "        mu[i] = (gam*np.exp(b0 + np.dot(x[:,i],b))+1)**(-1/gam)\n",
    "        y_true[i] = r*(1/mu[i]-1) # true y value\n",
    "\n",
    "    #simulate y value, via discrete sampling\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    for i in range(K):\n",
    "        for j in range(N_sim):\n",
    "            phi = rng.beta(s*mu[i],s*(1-mu[i]))\n",
    "            y_sim[i,j] = rng.negative_binomial(n = r, p = phi, size = 1)\n",
    "\n",
    "    y_sim = y_sim.astype(int)\n",
    "\n",
    "    print('simulation mse')\n",
    "    print(np.sqrt(np.mean((y_sim-y_true.reshape(K,1))**2)))\n",
    "    \n",
    "    \n",
    "    data = dict(x = x, y_sim = y_sim, y_true = y_true) \n",
    "    return data\n",
    "\n",
    "\n",
    "# start simulation\n",
    "\n",
    "pars = dict(\n",
    "#Number of simulation trials\n",
    "N_sim = 1,\n",
    "#trial bins\n",
    "K = 10,  #bins\n",
    "\n",
    "#NB-means\n",
    "r = 5,  \n",
    "#neurons numbers\n",
    "M = 20,\n",
    "#network weights\n",
    "b0= -0.5,\n",
    "#b = np.random.uniform(-0.9,0.9,M) #random select from -1 to 1; \n",
    "b = [-0.1,-0.2,-0.3,-0.4,\n",
    "     -0.1,-0.2,-0.3,-0.4,\n",
    "     0.1,0.2,0.3,0.4,\n",
    "     0.1,0.2,0.3,0.4,0.5,0.6,\n",
    "    -0.2,-0.3],\n",
    "#link function parameters\n",
    "loggam=np.log(7),\n",
    "#sigma for beta prior\n",
    "s = 50,\n",
    ")\n",
    "\n",
    "data = simulate(pars,2)\n",
    "x = data['x']\n",
    "y_sim = data['y_sim']\n",
    "y_true = data['y_true']\n",
    "\n",
    "N_sim = pars['N_sim']\n",
    "r = pars['r']\n",
    "M = pars['M']\n",
    "b0 = pars['b0']\n",
    "b = pars['b']\n",
    "loggam = pars['loggam']\n",
    "s = pars['s']\n",
    "K = pars['K']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5JhNiA667jT"
   },
   "source": [
    "## mcmc using stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "btbqqoE7cXeD",
    "outputId": "9113e0c3-a641-4ba4-aeb8-c1ff49543188"
   },
   "outputs": [],
   "source": [
    "model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;    // rows of data, bins \n",
    "  int<lower=1> P;    // columns of data, trials\n",
    "  int<lower=1> M;    // rows of neurons\n",
    "  real x[M,N];       // M neurons, N bins\n",
    "  int<lower=0> y[N,P]; // response\n",
    "}\n",
    "transformed data{\n",
    "  real y_sum[N];\n",
    "  for(i in 1:N){\n",
    "    y_sum[i] = sum(y[i,]);\n",
    "  }\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real<lower=1,upper=7> r; // neg. binomial mean parameter\n",
    "  real<lower=-1,upper=1>  b0;  // intercept\n",
    "  real<lower=-1,upper=1>  b[M];  // slopes\n",
    "  real<lower=30,upper=70> s;  //sigma\n",
    "  real<lower=0,upper=3> loggam; //gamma\n",
    "  real<lower=1e-9,upper=1-1e-9> phi[N];\n",
    "  real<lower=1e-9,upper=1e9> l[N];\n",
    "}\n",
    "\n",
    "\n",
    "transformed parameters{\n",
    "  real<lower=0,upper=1> mu[N]; \n",
    "  real<lower=0> alpha_0[N];\n",
    "  real<lower=0> beta_0[N];\n",
    "  real gam;\n",
    "  gam = exp(loggam);\n",
    "  for(i in 1:N){\n",
    "    mu[i] = (gam*exp(b0 + dot_product(x[,i],b))+1)^(-1/gam);\n",
    "    alpha_0[i] = s*mu[i];\n",
    "    beta_0[i] = s*(1-mu[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "model {   \n",
    "  // data model:\n",
    "  for(i in 1:N){\n",
    "    phi[i] ~ beta(alpha_0[i], beta_0[i]);\n",
    "    l[i] ~ gamma(r,phi[i]/(1-phi[i]));\n",
    "    for(j in 1:P){\n",
    "     y[i,j] ~ poisson(l[i]);\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] y_new_sod_glm;\n",
    "  for (n in 1:N){\n",
    "    y_new_sod_glm[n] = r*(1/mu[n]-1);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sm = pystan.StanModel(model_code=model, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EUSqvKbr2q6"
   },
   "source": [
    "### Optimization models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdAymJlv1LuK"
   },
   "outputs": [],
   "source": [
    "#objective function, calculate the maximum likelihood for SOD model\n",
    "def S0D_sum(x0, K, y, x):\n",
    "  r=x0[0]\n",
    "  b0=x0[1]\n",
    "  loggam=x0[2]\n",
    "  s=x0[3]\n",
    "  b=x0[4:]\n",
    "  import scipy.special as sc\n",
    "  LL_sum = np.zeros(y_sim.shape)\n",
    "  for i in range(y_sim.shape[0]):\n",
    "    gam = np.exp(loggam)\n",
    "    mu = (gam*np.exp(b0+np.dot(x[:,i],b))+1)**(-1/gam)\n",
    "    for j in range(y_sim.shape[1]):\n",
    "      LL_sum[i,j]=sc.gammaln(r+s*mu)+sc.gammaln(y_sim[i,j]+s-s*mu)+ \\\n",
    "          sc.gammaln(r+y_sim[i,j])+sc.gammaln(s)-\\\n",
    "          sc.gammaln(r+y_sim[i,j]+s)-sc.gammaln(r)-\\\n",
    "          sc.gammaln(s*mu)-sc.gammaln(s-s*mu)-sc.gammaln(y_sim[i,j]+1)\n",
    "\n",
    "\n",
    "  LL_sum = -1*np.sum(LL_sum)\n",
    "  return LL_sum\n",
    "\n",
    "\n",
    "#objective function, calculate the maximum likelihood for NBGLM model\n",
    "def NBGLM_sum(x0, K, y, x):\n",
    "  r=x0[0]\n",
    "  b0=x0[1]\n",
    "  loggam=x0[2]\n",
    "  b=x0[3:]\n",
    "  gam = np.exp(loggam)\n",
    "\n",
    "  import scipy.special as sc\n",
    "  LL_sum = np.zeros(y_sim.shape)\n",
    "\n",
    "  for i in range(y_sim.shape[0]):\n",
    "    mu = (gam*np.exp(b0+np.dot(x[:,i],b))+1)**(-1/gam)\n",
    "    for j in range(y_sim.shape[1]):\n",
    "      LL_sum[i,j]=sc.gammaln(r+y_sim[i,j])-\\\n",
    "                  sc.gammaln(y_sim[i,j]+1)- \\\n",
    "                  sc.gammaln(r)+\\\n",
    "                  r*np.log(mu)+\\\n",
    "                  y_sim[i,j]*np.log(1-mu)\n",
    "\n",
    "  LL_sum = -1*np.sum(LL_sum)\n",
    "  return LL_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKCrBdw4FTM5"
   },
   "source": [
    "### rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JqiA6QfIbbz"
   },
   "outputs": [],
   "source": [
    "# prediction rmse\n",
    "def rmse_nbglm(op,x,y_sim,y_true):\n",
    "  #get parameters\n",
    "  x_op = op.x\n",
    "  r_op=x_op[0]\n",
    "  b0_op=x_op[1]\n",
    "  loggam_op=x_op[2]\n",
    "  b_op=x_op[3:]\n",
    "  gam_op = np.exp(loggam_op)\n",
    "\n",
    "  K = x.shape[1]\n",
    "  response = np.zeros((K,))\n",
    "\n",
    "  for i in range(K):\n",
    "      mu = (gam_op*np.exp(b0_op+np.dot(x[:,i],b_op))+1)**(-1/gam_op)\n",
    "      response[i] = (r_op*(1/mu-1));\n",
    "\n",
    "  rmse_true = np.sqrt(np.mean((y_true-response)**2))\n",
    "  rmse_sim = np.sqrt(np.mean((y_sim-response.reshape(K,1))**2))\n",
    "\n",
    "  return rmse_true, rmse_sim, response\n",
    "\n",
    "def rmse_sod(op,x,y_sim,y_true):\n",
    "  #get parameters\n",
    "  x_op = op.x\n",
    "  r_op=x_op[0]\n",
    "  b0_op=x_op[1]\n",
    "  loggam_op=x_op[2]\n",
    "  s_op = x_op[3]\n",
    "  b_op=x_op[4:]\n",
    "  gam_op = np.exp(loggam_op)\n",
    "\n",
    "  K = x.shape[1]\n",
    "  response = np.zeros((K,))\n",
    "  N_sim = y_sim.shape[1]\n",
    "\n",
    "  for i in range(K):\n",
    "      mu = (gam_op*np.exp(b0_op+np.dot(x[:,i],b_op))+1)**(-1/gam_op)\n",
    "      #theta_eb = (N_sim*r_op+s_op*mu)/(N_sim*r_op+np.sum(y_sim,1)[i]+s_op);\n",
    "      response[i] = (r_op*(1/mu-1))\n",
    "\n",
    "  rmse_true = np.sqrt(np.mean((y_true-response)**2))\n",
    "  rmse_sim = np.sqrt(np.mean((y_sim-response.reshape(K,1))**2))\n",
    "\n",
    "  return rmse_true, rmse_sim, response\n",
    "    \n",
    "def rmse_mcmc(fit,x,y_sim,y_true):\n",
    "  K = x.shape[1]\n",
    "  mcmc_pred_y = np.mean(fit['y_new_sod_glm'], axis = 0)\n",
    "  rmse_true = np.sqrt(np.mean((y_true - mcmc_pred_y)**2))\n",
    "  rmse_sim = np.sqrt(np.mean((y_sim - mcmc_pred_y.reshape(K,1))**2))\n",
    "  return rmse_true, rmse_sim, mcmc_pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnjtwfqcIOAX"
   },
   "source": [
    "# Modeling (N_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ArWbUoQdykDe",
    "outputId": "9c9e2ec7-e9f0-4245-dd80-9e884febd405",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#start modeling\n",
    "history = dict()\n",
    "N_iter = 20\n",
    "\n",
    "#bounds sod\n",
    "bnds_sod = [[1,7],[0,10],[0,3],[30,70]]\n",
    "bnds_sod.extend([[-1,1]]*M)\n",
    "\n",
    "#bounds nbglm\n",
    "bnds_nbglm = [[1,7],[0,10],[0,3]]\n",
    "bnds_nbglm.extend([[-1,1]]*M)\n",
    "\n",
    "seeds = range(N_iter)\n",
    "for sim_i in range(N_iter):\n",
    "  #get simulation data\n",
    "  data = simulate(pars, seeds[sim_i])\n",
    "  x = data['x']\n",
    "  y_sim = data['y_sim']\n",
    "  y_true = data['y_true']\n",
    "\n",
    "  N_sim = pars['N_sim']\n",
    "  r = pars['r']\n",
    "  M = pars['M']\n",
    "  b0 = pars['b0']\n",
    "  b = pars['b']\n",
    "  loggam = pars['loggam']\n",
    "  s = pars['s']\n",
    "  K = pars['K']\n",
    "\n",
    "\n",
    "   #simulation N_iter times\n",
    "  #SOD model\n",
    "  x0 = [r,b0,loggam,s]\n",
    "  x0.extend(b)\n",
    "  t0 = time.time()\n",
    "  op_sod = scipy.optimize.minimize(S0D_sum, x0, args=(K, y_sim, x,), \\\n",
    "                                 bounds = bnds_sod, method='SLSQP')\n",
    "  t1 = time.time()\n",
    "  t_sod = t1-t0\n",
    "  if not op_sod.success:\n",
    "    print('not converge in sod model')\n",
    "\n",
    "  #rmse\n",
    "  rmse_sod_true, rmse_sod_sim, y_sod_est = rmse_sod(op_sod,x,y_sim,y_true) \n",
    "  #record\n",
    "  history['op_sod_'+str(sim_i)] = op_sod\n",
    "  history['t_sod_'+str(sim_i)] = t_sod\n",
    "  history['rmse_sod_true'+str(sim_i)] = rmse_sod_true\n",
    "  history['rmse_sod_sim'+str(sim_i)] = rmse_sod_sim\n",
    "  history['y_sod_est'+str(sim_i)] = y_sod_est\n",
    "\n",
    "  \n",
    "  #NBGLM model\n",
    "  x1 = [r,b0,loggam]\n",
    "  x1.extend(b)\n",
    "  t0 = time.time()\n",
    "  op_nbglm = scipy.optimize.minimize(NBGLM_sum, x1, bounds = bnds_nbglm,\n",
    "                              args=(K, y_sim, x,), \\\n",
    "                            method='SLSQP')\n",
    "  t1 = time.time()\n",
    "  t_nb = t1-t0\n",
    "  if not op_nbglm.success:\n",
    "    print('not converge in nbglm model')\n",
    "\n",
    "  #rmse\n",
    "  rmse_nbglm_true, rmse_nbglm_sim, y_nbglm_est = rmse_nbglm(op_nbglm,x,y_sim,y_true)\n",
    "  #record\n",
    "  history['op_nbglm_'+str(sim_i)] = op_nbglm\n",
    "  history['t_nbglm_'+str(sim_i)] = t_nb\n",
    "  history['rmse_nbglm_true'+str(sim_i)] = rmse_nbglm_true\n",
    "  history['rmse_nbglm_sim'+str(sim_i)] = rmse_nbglm_sim\n",
    "  history['y_nbglm_est'+str(sim_i)]=y_nbglm_est\n",
    "\n",
    "\n",
    "  #MCMC model\n",
    "  t0 = time.time()\n",
    "  fit = sm.sampling(data = dict(N = K, M = M, P = N_sim, y = y_sim, x=x),\n",
    "                  #pars = [\"b0\", \"b1\", 'b2', \"r\",'s','gam'],\n",
    "                  init= 'random',\n",
    "                  seed = 4,\n",
    "                  iter = 1000, \n",
    "                  n_jobs = 4,\n",
    "                  chains = 4,\n",
    "                  #control = dict(adapt_delta=1,max_treedepth=12),\n",
    "                  verbose = True)\n",
    "  t1 = time.time()\n",
    "  t_mcmc = t1-t0\n",
    "\n",
    "  #rmse\n",
    "  rmse_mcmc_true, rmse_mcmc_sim, y_mcmc_est = rmse_mcmc(fit,x,y_sim,y_true)\n",
    "  #record\n",
    "  history['mcmc_fit'+str(sim_i)] = fit\n",
    "  history['mcmc_t'+str(sim_i)] = t_mcmc\n",
    "  history['rmse_mcmc_true'+str(sim_i)] = rmse_mcmc_true\n",
    "  history['rmse_mcmc_sim'+str(sim_i)] = rmse_mcmc_sim\n",
    "  history['y_mcmc_est'+str(sim_i)] = y_mcmc_est\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UWo3ruJGNrlp"
   },
   "source": [
    "## Visualization of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vcGe6Zc_KV1x"
   },
   "outputs": [],
   "source": [
    "def plot_b(b_pred, b_true, name):\n",
    "  b_mean = np.mean(b_pred, axis = 0)\n",
    "  b_error = stats.sem(b_pred,axis =0)\n",
    "\n",
    "  import matplotlib.pyplot as plt\n",
    "  from matplotlib.patches import Circle\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(3, 3))\n",
    "\n",
    "  #line\n",
    "  x_plot = np.linspace(-1,1,100)\n",
    "  y_plot = x_plot\n",
    "  plt.plot(x_plot, y_plot, '-b', label='y=x')\n",
    "\n",
    "  #points\n",
    "  for i in range(len(b_true)):\n",
    "      p = Circle((b_true[i], b_mean[i]), np.sqrt(b_error[i]/np.pi), alpha = 0.4)\n",
    "      ax.add_artist(p)\n",
    "  # plt.scatter(b,b_pred_op_mean,s=np.sqrt(np.abs(b_pred_op_error)))\n",
    "\n",
    "  plt.ylim([-1.2,1.2])\n",
    "  plt.xlim([-1.2,1.2])\n",
    "  plt.xlabel('True weights')\n",
    "  plt.ylabel('Estimated weights')\n",
    "  plt.title(name)\n",
    "  plt.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(rmse, order):\n",
    "  #order: true,0; sim: 1\n",
    "  import scipy.stats\n",
    "  rmse_mean = np.mean(rmse, axis = 0)\n",
    "  rmse_error = stats.sem(rmse,axis =0)/np.abs(rmse_mean)\n",
    "\n",
    "  return rmse_mean[order],rmse_error[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DILwRoYXI-T-"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# true, sim\n",
    "rmse_mcmc_arr = np.zeros((N_iter,2))\n",
    "rmse_sod_arr = np.zeros((N_iter,2))\n",
    "rmse_nbglm_arr = np.zeros((N_iter,2))\n",
    "for i in range(N_iter):\n",
    "  #mcmc\n",
    "  rmse_mcmc_arr[i,0] = history['rmse_mcmc_true'+str(i)]\n",
    "  rmse_mcmc_arr[i,1] = history['rmse_mcmc_sim'+str(i)]\n",
    "  \n",
    "\n",
    "  #sod\n",
    "  rmse_sod_arr[i,0] = history['rmse_sod_true'+str(i)]\n",
    "  rmse_sod_arr[i,1] = history['rmse_sod_sim'+str(i)]\n",
    "  \n",
    "\n",
    "  #nbglm\n",
    "  rmse_nbglm_arr[i,0] = history['rmse_nbglm_true'+str(i)]\n",
    "  rmse_nbglm_arr[i,1] = history['rmse_nbglm_sim'+str(i)]\n",
    "  \n",
    "\n",
    "rmse_mcmc_mean,rmse_mcmc_error = get_rmse(rmse_mcmc_arr, 0)\n",
    "rmse_sod_mean,rmse_sod_error = get_rmse(rmse_sod_arr, 0)\n",
    "rmse_nbglm_mean,rmse_nbglm_error = get_rmse(rmse_nbglm_arr, 0)\n",
    "\n",
    "print(rmse_mcmc_mean,rmse_sod_mean,rmse_nbglm_mean)\n",
    "print(rmse_mcmc_error,rmse_sod_error,rmse_nbglm_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgxRcd2NmoA9"
   },
   "source": [
    "### time for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gb8pdbSOlUEr"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# true, sim\n",
    "t_mcmc = np.zeros((N_iter,1))\n",
    "t_sod = np.zeros((N_iter,1))\n",
    "t_nbglm = np.zeros((N_iter,1))\n",
    "for i in range(N_iter):\n",
    "  # mcmc\n",
    "  t_mcmc[i,0] = history['mcmc_t'+str(sim_i)]\n",
    "\n",
    "  #sod\n",
    "  t_sod[i,0] = history['t_sod_'+str(i)]\n",
    "\n",
    "  #nbglm\n",
    "  t_nbglm[i,0] = history['t_nbglm_'+str(i)]\n",
    "    \n",
    "t_mcmc_mean = np.mean(t_mcmc)\n",
    "t_sod_mean = np.mean(t_sod)\n",
    "t_nbglm_mean = np.mean(t_nbglm) \n",
    "\n",
    "print(t_mcmc_mean, t_sod_mean,t_nbglm_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimated spike counts with real spike couts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalculate y true and y sim\n",
    "for i in range(N_iter):\n",
    "  #get simulation data\n",
    "  data = simulate(pars, seeds[i])\n",
    "  x = data['x']\n",
    "  y_sim = data['y_sim']\n",
    "  y_true = data['y_true']\n",
    "\n",
    "  #mcmc\n",
    "  fit = history['mcmc_fit'+str(i)]\n",
    "  #sod\n",
    "  op_sod = history['op_sod_'+str(i)]\n",
    "\n",
    "  #nbglm\n",
    "  op_nbglm = history['op_nbglm_'+str(i)]\n",
    "\n",
    "  if i == 0:\n",
    "    y_response = y_true\n",
    "    mcmc_response = rmse_mcmc(fit,x,y_sim,y_true)[2]\n",
    "    sod_response = rmse_sod(op_sod,x,y_sim,y_true)[2]\n",
    "    nbglm_response = rmse_nbglm(op_nbglm,x,y_sim,y_true)[2]\n",
    "  else:\n",
    "    y_response = np.append(y_response, y_true)\n",
    "    mcmc_response = np.append(mcmc_response, rmse_mcmc(fit,x,y_sim,y_true)[2])\n",
    "    sod_response = np.append(sod_response, rmse_sod(op_sod,x,y_sim,y_true)[2])\n",
    "    nbglm_response = np.append(nbglm_response, rmse_nbglm(op_nbglm,x,y_sim,y_true)[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sod_response, y_response, 'o')\n",
    "plt.xlabel('true spike counts')\n",
    "plt.ylabel('estimate spike counts')\n",
    "plt.title('SODS model')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(nbglm_response, y_response, 'o')\n",
    "plt.xlabel('true spike counts')\n",
    "plt.ylabel('estimate spike counts')\n",
    "plt.title('NBGLM model')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(mcmc_response, y_response, 'o')\n",
    "plt.xlabel('true spike counts')\n",
    "plt.ylabel('estimate spike counts')\n",
    "plt.title('MCMC model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6mMhnHELyfa"
   },
   "source": [
    "## SAVE RECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhRttGFdUBEL"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "file_id = 'K'+str(K)+'_Sim'+str(N_sim)+\\\n",
    "'_gam_'+str(np.int(np.round(np.exp(loggam))))+\\\n",
    "'_s'+str(s)+'_r'+str(r)+'_Ne'+str(M)+'.pkl'\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    "\n",
    "# Saving the objects:\n",
    "with open(file_id, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump({'model':sm, \n",
    "                 'history':history,\n",
    "                 'pars':pars,\n",
    "                 'rmse':[rmse_mcmc_mean,rmse_mcmc_error,\n",
    "                         rmse_sod_mean,rmse_sod_error,\n",
    "                         rmse_nbglm_mean,rmse_nbglm_error],\n",
    "                 't':[t_mcmc_mean,t_sod_mean,t_nbglm_mean],\n",
    "                'p':[p_mcmc, p_sod, p_nbglm]},\n",
    "                f, protocol=-1)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-5JhNiA667jT"
   ],
   "name": "spike_counts.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
