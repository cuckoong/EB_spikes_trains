import scipy
import scipy.io
import matplotlib.pyplot as plt
import os
from models import SOD, POISSON
from sklearn.model_selection import GridSearchCV, cross_validate
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
import numpy as np
from sklearn.pipeline import Pipeline
import pandas as pd


def my_score_fun(clf, X, y):
    x0 = clf['clf'].op.x
    possitive_LLsum = -1 * clf['clf'].objective(x0, X, y)
    return possitive_LLsum


def my_mse_fun(clf, X, y):
    x0 = clf['clf'].op.x
    y_pred = clf.predict(X)
    mse = mean_squared_error(y, y_pred)
    return mse

result = dict()
scores_fun = {'ll_f':my_score_fun,
              'mse_f':my_mse_fun}

wkdir = '/Users/panpan/Documents/EB_spikes/exerimental_data/'
files = os.listdir(wkdir)
for file in files:
    LL_list = []
    mse_list = []

    spike_count = scipy.io.loadmat(wkdir+file)['spike_count']
    spike_count = spike_count.T

    for i in range(spike_count.shape[1]):
        # preparing training and test data for each neuron
        y = spike_count[:, i]
        X = np.delete(spike_count, i, axis=1)

        lam = [0.1, 1, 10]
        param_grid = dict(clf__lam=lam)

        pipe = Pipeline([
            ('scale', StandardScaler()),
            ('clf', SOD())])

        grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=1, verbose=2, scoring=my_score_fun)
        grid.fit(X, y)

        pipe_op = Pipeline([
            ('scale', StandardScaler()),
            ('clf', SOD(lam=grid.best_params_['clf__lam']))])
        # cv
        grid_cv = cross_validate(pipe_op, X, y, scoring=scores_fun, cv=5, n_jobs=-1)
        LL_list.extend(grid_cv['test_ll_f'])
        mse_list.extend(grid_cv['test_mse_f'])

        df = dict(LL=LL_list,mse=mse_list)
        df = pd.DataFrame(df)
        df.to_csv('file_{}_neuron_{}_sod.csv'.format(file[:-4],i))
